<hr>
<p>title: Nginx反向代理与集群的session共享<br>date: 2019-09-23 17:48:30<br>tags: 分布式</p>
<h2 id="categories-分布式"><a href="#categories-分布式" class="headerlink" title="categories: 分布式"></a>categories: 分布式</h2><h1 id="Nginx简介"><a href="#Nginx简介" class="headerlink" title="Nginx简介"></a>Nginx简介</h1><p>Nginx (发音为[eng ine x])专为性能优化而开发，其最知名的优点是它的稳定性和低系统资源消耗，以及对并发连接的高处理能力(单台物理服务器可支持30000～50000个并发连接，tomcat通常是几百，不超过1000个)，<br>是一个高性能的 HTTP 和反向代理服务器，也是一个IMAP/POP3/SMTP 代理服务器。</p>
<p>关于Nginx服务器，除了其高效性和稳定性的优点之外，我们最常使用的主要是其<strong>反向代理</strong>和<strong>负载均衡</strong>,以及动静分离功能。</p>
<h2 id="1-1正向代理"><a href="#1-1正向代理" class="headerlink" title="1.1正向代理"></a>1.1正向代理</h2><p>通常，我们可以通过ip地址来直接访问网络中的某台确定的主机（更确切的说应该是通过socket套接字来访问确定主机中的某个确定的进程）。<img src="D:\blog\WJJ711\source\_posts\分布式\Nginx反向代理与集群的session共享\1.png" alt="1"></p>
<p><img src="D:\blog\WJJ711\source\_posts\分布式\Nginx反向代理与集群的session共享\2.png" alt="2"></p>
<p>假设服务器B，能够将客户端的请求转发给服务器A，同时服务器B又能够将服务器A的响应转发给客户端，那么显而易见，我们就可以通过访问服务器B，从而达到访问服务器A的目的。<img src="D:\blog\WJJ711\source\_posts\分布式\Nginx反向代理与集群的session共享\3.png" alt="3"></p>
<p>现在，我们再来看客户端访问服务器A的过程，客户端通过服务器B同样达到了访问服务器A的目的，但是，请注意此时:服务器B似乎是作为客户端访问服务器A的一个“媒介”，而发挥作用这种情况下。</p>
<h2 id="1-2反向代理"><a href="#1-2反向代理" class="headerlink" title="1.2反向代理"></a>1.2反向代理</h2><p>与正向代理服务器不同，反向代理服务器的作用，不在仅仅是充当能够访问到目标服务器的“媒介”或者说，是作为客户端访问目标服务器的代理。</p>
<p>反向代理是在服务器端（如Web服务器）作为代理使用，而不是客户端。客户端通过正向代理可以访问很多不同的资源，而反向代理是很多客户端都通过它访问不同后端服务器上的资源，而不需要知道这些后端服务器的存在，而以为所有资源都来自于这个反向代理服务器。</p>
<p><img src="D:\blog\WJJ711\source\_posts\分布式\Nginx反向代理与集群的session共享\4.png" alt="4"></p>
<h2 id="1-3负载均衡-load-balancing"><a href="#1-3负载均衡-load-balancing" class="headerlink" title="1.3负载均衡 load balancing"></a>1.3负载均衡 load balancing</h2><p>在上图中，我们可以看到，服务器A，B之间的功能完全相同，可以相互替代，通过将原本由一个服务器负责处理的任务，分担给多台服务器，从而减小了各个服务器的并发压力，同时扩展了服务器的带宽，从而提高了吞吐量——这就是负载均衡。</p>
<p>负载平衡是一种计算机网络技术，用来在多个计算机（计算机集群）、网络、CPU、磁盘驱动器或其他资源中分配负责，以达到最优化资源利用，最大化吞吐率，最小化响应时间，同时避免过载的目的。</p>
<p>上图中多台服务器，实际上指的是集群。</p>
<p><strong>集群和分布式的关系：</strong></p>
<p>小饭店原来只有一个厨师，切菜，洗菜，备料，炒菜，全干。后来客人多了，厨房一个厨师忙不过来了，又请了一个厨师，两个厨师都能抄一样的菜，这两个厨师的关系就是集群。</p>
<p>为了让厨师专心炒菜，把菜做到极致，又请了个配菜师负责切菜，备料，备菜，厨师和配菜师的关系是分布式，后来发现，一个配菜师也忙不过来，又请了一个配菜师，这两个配菜师的关系就是集群。</p>
<h2 id="1-4动静分离"><a href="#1-4动静分离" class="headerlink" title="1.4动静分离"></a>1.4动静分离</h2><p>对于一些基本很少发生变化的静态资源，可以直接放在Nginx服务器上，当客户端访问这些静态资源时，Nginx就可以直接返回给客户端，而不用在访问服务器集群，从而节省了部分请求和响应的时间。</p>
<p>这样一来，当客户端访问Nginx服务器时，当客户端访问静态资源时，Nginx就将静态资源直接返回给客户端，当客户端访问的是动态资源的时候，Nginx才会访问集群，这样一来，就实现了动态资源和静态资源的分离，从而提高了系统的吞吐量。</p>
<h1 id="Nginx基本操作"><a href="#Nginx基本操作" class="headerlink" title="Nginx基本操作"></a>Nginx基本操作</h1><p>在/user/local/nginx/sbin下</p>
<p>启动nginx</p>
<p><code>./nginx</code></p>
<p>重启nginx：</p>
<p><code>./nginx -s reload</code></p>
<p>关闭nginx</p>
<pre><code>./nginx -s stop  :快速停止nginx  
           quit  ：完整有序的停止nginx  
</code></pre><p>其他的停止nginx方式：</p>
<p><code>ps -ef | grep nginx</code></p>
<pre><code>kill -QUIT 主进程号     ：从容停止Nginx  
kill -TERM 主进程号     ：快速停止Nginx  
pkill -9 nginx          ：强制停止Nginx  
</code></pre><p>实例：</p>
<pre><code>upstream tomcat_server{
ip_hash;
server 192.168.11.68:20201;
server 192.168.11.69:20201 weight=100 down;
server 192.168.11.70:20201 weight=100;
server 192.168.11.71:20201 weight=100 backup;
server 192.168.11.72:20201 weight=100 max_fails=3 fail_timeout=30s;
}
</code></pre><p>说明</p>
<pre><code>1)、down 表示当前的server暂时不参与负载
2)、weight 默认为1.weight越大，负载的权重就越大。
3)、backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。
4)、上例中192.168.11.72:20201 设置最大失败次数为 3，也就是最多进行 3 次尝试，且超时时间为 30秒。max_fails 的默认值为 1，fail_timeout 的默认值是 10s。
注意，当upstream中只有一个 server 时，max_fails 和 fail_timeout 参数可能不会起作用。
</code></pre><h1 id="集群的session共享"><a href="#集群的session共享" class="headerlink" title="集群的session共享"></a>集群的session共享</h1><h2 id="2-1-Session"><a href="#2-1-Session" class="headerlink" title="2.1 Session"></a>2.1 Session</h2><p>使用了Nginx和集群，对客户端的请求做了负载均衡，从系统的吞吐量的角度来看，这无疑是很好的，但是，随之而来的一个问题，就是session共享的问题：</p>
<p><img src="D:\blog\WJJ711\source\_posts\分布式\Nginx反向代理与集群的session共享\5.png" alt="5"></p>
<p>如图，在浏览器的一次会话中，两次访问Nginx代理的集群，Nginx分别把这两次请求，分配给了不同的服务器来处理，于是出现了这样一个问题：</p>
<ul>
<li><p>首先，session只产生和存在于单个服务器中。</p>
</li>
<li><p>明明是逻辑上的一次会话，因为实际访问了两台不同的服务器，所以两台服务器会分别为针对它们各自的请求而新建会话（假设两台服务器都是被该浏览器第一次访问）。</p>
</li>
<li><p>于是，一次会话的信息，实际上被两个服务器中的两个session所存储，每个session实际只存储，这次会话的部分信息。</p>
</li>
<li><p>这种情况下，我们通过nginx访问同一个页面多次，可能会访问不同服务器上的同一个页面，session不同步的问题会导致用户必须在同一个页面登录两次。</p>
</li>
</ul>
<h2 id="2-2Session共享问题的解决"><a href="#2-2Session共享问题的解决" class="headerlink" title="2.2Session共享问题的解决"></a>2.2Session共享问题的解决</h2><h3 id="2-2-1-Session-sticky"><a href="#2-2-1-Session-sticky" class="headerlink" title="2.2.1 Session sticky"></a>2.2.1 Session sticky</h3><p>这种解决方案的思路，比较简单，就是用一个hash算法，将对某ip的访问映射到一台确定的服务器上，这样针对某ip的访问就固定到一台确定的服务器，不同的ip访问不同的服务器。</p>
<p>同时，这种解决方案也有一定的局限性：</p>
<ul>
<li><p>一旦tomcat所在的某台服务器重新启动，那么与这台服务器相关的会话信息就会丢失，如果用户此时再次访问相同网页，需要重新登录。</p>
</li>
<li><p>代理服务器需要计算，保存，维护ip和相应服务器之间的映射关系，内存消耗大。</p>
</li>
</ul>
<h3 id="2-2-2-Session-Replication"><a href="#2-2-2-Session-Replication" class="headerlink" title="2.2.2 Session Replication"></a>2.2.2 Session Replication</h3><p>这种解决方案的思路是，每个服务器上，都有集群中其他服务器中session数据的副本，同时增加服务器之间的数据同步功能，通过服务器之间的同步保证session数据在各个服务器之间的一致性。</p>
<p>这种解决方案，不再像session sticky中那样要求Nginx服务器做一些处理，但是这种方式的局限性也很大：</p>
<ul>
<li><p>一旦session数据发生变化，所有的服务器都需要同步变化的session数据，而这种同步会消耗带宽。</p>
</li>
<li><p>同时，由于每台服务器都存储了其他所有服务器上的session副本， 冗余数据也占用了服务器的存储空间 </p>
</li>
</ul>
<p><a href="https://www.2cto.com/net/201701/584323.html">https://www.2cto.com/net/201701/584323.html</a></p>
<p><strong>两个关键配置：</strong></p>
<p>Tomcat的server.xml</p>
<p><img src="D:\blog\WJJ711\source\_posts\分布式\Nginx反向代理与集群的session共享\6.png" alt="6"></p>
<p>应用的web.xml</p>
<p><img src="D:\blog\WJJ711\source\_posts\分布式\Nginx反向代理与集群的session共享\7.png" alt="7"></p>
<h3 id="2-2-3-Session数据集中控制"><a href="#2-2-3-Session数据集中控制" class="headerlink" title="2.2.3  Session数据集中控制"></a>2.2.3  Session数据集中控制</h3><p>这种解决方案的思路是，将所有服务器上的session数据集中存储和管理，这样一来，所有的服务器的session在集群中只需要有一份。</p>
<p>这种解决方案，由于session并不存储在本地，对session的访问需要通过网络，这样可能就会产生访问的延时，以及不稳定性，不过我们通信基本都是发生在内网，问题不大，如果集中存储Session的机器或者集群有问题，就会影响我们的应用。</p>
<p>Redis  内存数据库  Nosql </p>
